<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Related Work Page</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            padding: 20px;
        }

        h1 {
            margin-bottom: 20px;
        }

        .image-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            grid-gap: 20px;
        }

        .image-grid img {
            width: 100%;
            height: auto;
        }
    </style>
</head>

<body>
    <h1>Related Work</h1>

    <p>Projects, demos, and blogs showcasing real-time detection of certain intralogistics objects like pallets are abundant; to our knowledge, most of them almost exclusively focus on detection metrics of intralogistics objects alone, without inference broadcasting goals nor detailed qualification of detection asset context (i.e. detector module speed with respect to the ground, etc), and on comparative performance of earlier versions of YOLO architectures vs alternatives, using a specific training dataset, against specific contextual target conditions:</p>

    <ul>
        <li>Near optimal scenery, including favorable illumination,</li>
        <li>Shorter range distance, and,</li>
        <li>With few, if any, considerations of core and ancillary requirements and variances in environment variables, such as:
            <ul>
                <li>Scene “density” i.e. single pallets in aisles vs an unstacked clusters of pallets in distant corners, possibly directly inaccessible by forklift</li>
                <li>Partial pallet occlusion from plastic pallet wrap, not just other objects,</li>
                <li>Illumination,</li>
                <li>Speed of the vehicle to which the inference module is affixed,</li>
                <li>Performance at medium to longer detection distance range,</li>
                <li>Near real-time telemetric inference transmission</li>
            </ul>
        </li>
    </ul>

    <p>YOLOv9, released in late February 2024 and <a href="https://github.com/WongKinYiu/yolov9">available on Github</a>, is also incorporated into Ultralytics. We are exploring its capabilities and performance in our application and scenarios.</p>

    <h2>2.1 Object Detection</h2>

    <p>Modern CNN-based object detection models go about their business in two-stage and single-stage fashion. The single-stage approach pioneered by YOLO detects objects in one pass. YOLO-based iterations directly predict bounding boxes around object class instances, together with confidence values.</p>

    <h2>2.2 Real-time Object Detection</h2>

    <p>Prior work in real-time detection for intralogistics benefit includes the following:</p>

        Y. Li et al., "Pallet detection and localization with RGB image and depth data using deep learning techniques," <em>2021 6th International Conference on Automation, Control and Robotics Engineering (CACRE)</em>, Dalian, China, 2021, pp. 306-310, doi: 10.1109/CACRE52464.2021.9501390.
        <ul>
            <li>The paper introduces a new method called PILA for detecting and localizing pallets using RGB images and depth data with deep learning techniques. The algorithm employs a deep neural network to identify and locate pallets in RGB images, aligns point cloud data with labeled regions of interest, extracts the pallet's front-face plane, and determines its orientation and centric points. The approach achieves a 3D localization accuracy of 1cm and an angle resolution of 0.4 degrees at a distance of 3m, with a running time of less than 700 ms. The research emphasizes the significance of accurate pallet detection for unmanned forklift robots in logistics applications, particularly in the context of the COVID-19 pandemic. Key aspects include challenges in pallet detection, the algorithm's advantages, and the use of SSD architecture for pallet recognition in RGB images.</li>
        </ul>
        
        Diwan, T., Anirudh, G. & Tembhurne, J.V. “Object detection using YOLO: challenges, architectural successors, datasets and applications,” <em>Multimed Tools Appl 82</em>, 2023, pp. 9243–9275, doi:10.1007/s11042-022-13644-y    
        <ul>
            <li>Pallet identification and localization algorithm based on RGB image and depth data. Using a Deep Neural Network, the pallet’s point cloud data is correlated with the labeled region of interest. We will use the results as a reference baseline.</li>
            <li>The paper reviews object detection, focusing on YOLO model and its successors. It discusses two-stage vs. single-stage detectors, highlighting differences in architecture and performance metrics. YOLO and its successors show improved detection accuracy and faster inference times, making them popular in various applications. Challenges in object detection include multi-scale training and detection of smaller objects. The paper also addresses the evolution of object detectors and related works.</li>
        </ul>

        M. Zaccaria, R. Monica and J. Aleotti, "A Comparison of Deep Learning Models for Pallet Detection in Industrial Warehouses," <em>2020 IEEE 16th International Conference on Intelligent Computer Communication and Processing (ICCP)</em>, Cluj-Napoca, Romania, 2020, pp. 417-422, doi: 10.1109/ICCP51029.2020.9266168.
        <ul>
            <li>A Comparison of Deep Learning Models for Pallet Detection in Industrial Warehouses</li>
            <li>The paper discusses the use of convolutional neural networks (CNNs) for automatic pallet detection in industrial settings using a single RGB camera. It compares the performance of three CNN models - Faster R-CNN, SSD, and YOLOv4 - in identifying pallet front sides and pockets. The study includes a dataset collected from a warehouse and evaluates the models based on their ability to detect pallets. Results show that Faster R-CNN and SSD outperform YOLOv4 in pallet detection. The decision block in the proposed method filters out false positives and ensures safe and reliable autonomous guided vehicle tasks.</li>
        </ul>
        
        Syu, JL., Li, HT., Chiang, JS. et al, “A computer vision assisted system for autonomous forklift vehicles in real factory environment,” <em>Multimed Tools Appl 76</em>, 2017, pp.18387–18407, doi: 10.1007/s11042-016-4123-6
        <ul>
            <li>A computer vision assisted system for autonomous forklift vehicles in real factory environment</li>
            <li>The paper introduces a computer vision system for autonomous forklift vehicles in real factory settings, focusing on pallet detection using a monocular vision system. It utilizes Haar-like features and the Adaboost algorithm for efficient pallet detection. The system aims to provide a cost-effective solution for pallet detection in industrial environments, improving accuracy and speed.</li>
        </ul>
        
        C. Rennie, R. Shome, K. E. Bekris and A. F. De Souza, "A Dataset for Improved RGBD-Based Object Detection and Pose Estimation for Warehouse Pick-and-Place," <em>IEEE Robotics and Automation Letters, vol. 1, no. 2</em>, pp. 1179-1185, July 2016, doi: 10.1109/LRA.2016.2532924.
        <ul>
            <li>The paper introduces a dataset for improving RGBD-based object detection and pose estimation in warehouse pick-and-place tasks. The dataset includes thousands of images with ground truth data for objects used in the Amazon Picking Challenge, focusing on challenges like low illumination and clutter. It emphasizes the importance of accurate pose estimation for successful object manipulation in warehouse shelves and highlights the need for robust algorithms in such environments. The dataset aims to enhance robotic perception solutions for warehouse picking by providing tools for evaluation and improvement.</li>
            <li>If we get to expand our project further from pallet detection to include other intralogistics assets, we can refer to this dataset. We know of relevant needs on empty pallet rack (shelving) space and pallet floor buffer overflow incidence knowledge, for real-time and longitudinal operational optimization.</li>
        </ul>
</body>

</html>
